{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets.dtu import DTUDataset\n",
    "from datasets import find_dataset_def\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # this increases inference speed a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_rcmvsnet_dtu import args, testlist, Interval_Scale\n",
    "from train_rcmvsnet import test_sample_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.mvsnet import CascadeMVSNet\n",
    "from models.casmvsnet import *\n",
    "# from utils import load_ckpt\n",
    "# from inplace_abn import ABN\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "test_model_loss = cas_mvsnet_loss\n",
    "args.num_view = 4\n",
    "args.loadckpt ='./rc-mvsnet1/model_000010_cas.ckpt'\n",
    "# numdepth = 192\n",
    "# interval_scale = 1.06\n",
    "# max_h = 1200\n",
    "# max_w = 1600\n",
    "logger = SummaryWriter('./depth_test_results')\n",
    "\n",
    "# dataset, dataloader\n",
    "MVSDataset = find_dataset_def(args.dataset)\n",
    "test_dataset = MVSDataset(args.testpath, testlist, \"test\", args.num_view, args.numdepth, Interval_Scale,\n",
    "                            max_h=args.max_h, max_w=args.max_w, fix_res=args.fix_res)\n",
    "TestImgLoader = DataLoader(test_dataset, args.batch_size, shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "\n",
    "model = CascadeMVSNet_eval(refine=False, ndepths=[int(nd) for nd in args.ndepths.split(\",\") if nd],\n",
    "            depth_interals_ratio=[float(d_i) for d_i in args.depth_inter_r.split(\",\") if d_i],\n",
    "            share_cr=args.share_cr,\n",
    "            cr_base_chs=[int(ch) for ch in args.cr_base_chs.split(\",\") if ch],\n",
    "            grad_method=args.grad_method)\n",
    "\n",
    "state_dict = torch.load(args.loadckpt, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(state_dict['model'], strict=True)\n",
    "# model = nn.DataParallel(model)\n",
    "# model.cuda()\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "with torch.no_grad():\n",
    "    avg_test_scalars = DictAverageMeter()\n",
    "    for batch_idx, sample in enumerate(TestImgLoader):\n",
    "        start_time = time.time()\n",
    "        global_step = batch_idx\n",
    "        do_summary = global_step % 48 == 0\n",
    "        loss, scalar_outputs, image_outputs = test_sample_depth(model, test_model_loss, sample, args)\n",
    "        if do_summary:\n",
    "            save_scalars(logger, 'test', scalar_outputs, global_step)\n",
    "            save_images(logger, 'test', image_outputs, global_step)\n",
    "            print(\"Iter {}/{}, test loss = {:.3f}, depth loss = {:.3f}, thres2mm_accu = {:.3f},thres4mm_accu = {:.3f},thres8mm_accu = {:.3f},thres2mm_error = {:.3f},thres4mm_error = {:.3f},thres8mm_error = {:.3f},time = {:3f}\".format(\n",
    "                                                                batch_idx,\n",
    "                                                                len(TestImgLoader), loss,\n",
    "                                                                scalar_outputs[\"depth_loss\"],\n",
    "                                                                scalar_outputs[\"thres2mm_accu\"],\n",
    "                                                                scalar_outputs[\"thres4mm_accu\"],\n",
    "                                                                scalar_outputs[\"thres8mm_accu\"],\n",
    "                                                                scalar_outputs[\"thres2mm_error\"],\n",
    "                                                                scalar_outputs[\"thres4mm_error\"],\n",
    "                                                                scalar_outputs[\"thres8mm_error\"],\n",
    "                                                                time.time() - start_time))\n",
    "        avg_test_scalars.update(scalar_outputs)\n",
    "        del scalar_outputs, image_outputs\n",
    "\n",
    "    save_scalars(logger, 'fulltest', avg_test_scalars.mean(), global_step)\n",
    "    print(\"avg_test_scalars:\", avg_test_scalars.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, sample in enumerate(TestImgLoader):\n",
    "        sample_cuda = tocuda(sample)\n",
    "        start_time = time.time()\n",
    "        outputs = model(sample_cuda[\"imgs\"], sample_cuda[\"proj_matrices\"], sample_cuda[\"depth_values\"])\n",
    "        end_time = time.time()\n",
    "        outputs = tensor2numpy(outputs)\n",
    "        del sample_cuda\n",
    "        filenames = sample[\"filename\"]\n",
    "        cams = sample[\"proj_matrices\"][\"stage{}\".format(num_stage)].numpy()\n",
    "        # imgs = sample[\"imgs\"].numpy()\n",
    "        imgs = sample[\"imgs\"]\n",
    "        depth_values=sample[\"depth_values\"]\n",
    "        depth_start,depth_end =depth_values[0][0],depth_values[0][-1]\n",
    "        \n",
    "        # print(\"sample[imgs]: {}\".format(sample[\"imgs\"].shape))\n",
    "        # imgs = inv_normalize(sample[\"imgs\"].squeeze()).unsqueeze(dim=0).numpy()\n",
    "        # imgs = sample[\"imgs_raw\"].numpy()\n",
    "        print('Iter {}/{}, Time:{} Res:{}'.format(batch_idx, len(TestImgLoader), end_time - start_time, imgs[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize an example depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "plt.imshow(unpreprocess(imgs[0]).permute(1,2,0))\n",
    "plt.imshow(visualize_depth(depths['level_0']*masks['level_0']).permute(1,2,0), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference on this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "with torch.no_grad():\n",
    "    results = model(imgs.unsqueeze(0).cuda(), proj_mats.unsqueeze(0).cuda(), init_depth_min, depth_interval)\n",
    "    torch.cuda.synchronize()\n",
    "print('inference time', time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unpreprocess(imgs[0]).permute(1,2,0))\n",
    "plt.imshow(visualize_depth(results['depth_0'][0]).permute(1,2,0), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results['confidence_2'][0].cpu().numpy()>0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference: show pixels whose absolute depth error is less than 2mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2 = torch.abs(depths['level_0']-results['depth_0'].cpu())[0]<2\n",
    "plt.imshow(err2);\n",
    "print('acc_2mm :', ((err2.float()*masks['level_0']).sum()/masks['level_0'].sum()).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLOPs example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# Load the model checkpoint\n",
    "model = MyModel()\n",
    "model.load_state_dict(torch.load('path/to/checkpoint.pth'))\n",
    "\n",
    "# Calculate FLOPs\n",
    "with torch.cuda.device(0):\n",
    "    macs, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True,\n",
    "                                             print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
